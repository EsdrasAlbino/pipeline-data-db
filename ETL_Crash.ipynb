{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuqGfgwfrwl1"
   },
   "source": [
    "# üìä Pipeline de Dados - Acidentes de Tr√¢nsito (2019-2021)\n",
    "\n",
    "## üõ†Ô∏è Imports e Configura√ß√µes Iniciais\n",
    "\n",
    "Este notebook implementa pipelines ETL e ELT para integra√ß√£o de dados de acidentes de tr√¢nsito de tr√™s anos consecutivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2485.26s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: sqlalchemy in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.0.42)\n",
      "Requirement already satisfied: openpyxl in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from sqlalchemy) (4.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from sqlalchemy) (4.14.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: et-xmlfile in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/esdrasalbino/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Todas as bibliotecas foram importadas com sucesso!\n",
      "üì¶ Pandas vers√£o: 2.3.1\n",
      "üì¶ SQLAlchemy vers√£o: 2.0.42\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Todas as bibliotecas foram importadas com sucesso!\n",
      "üì¶ Pandas vers√£o: 2.3.1\n",
      "üì¶ SQLAlchemy vers√£o: 2.0.42\n"
     ]
    }
   ],
   "source": [
    "# Instalar pacotes necess√°rios no ambiente do notebook\n",
    "%pip install pandas numpy sqlalchemy openpyxl\n",
    "\n",
    "# Bibliotecas para manipula√ß√£o de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliotecas para banco de dados\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "print(\"‚úÖ Todas as bibliotecas foram importadas com sucesso!\")\n",
    "print(f\"üì¶ Pandas vers√£o: {pd.__version__}\")\n",
    "print(f\"üì¶ SQLAlchemy vers√£o: {sqlalchemy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2041,
     "status": "ok",
     "timestamp": 1754516962236,
     "user": {
      "displayName": "Guilherme Campelo",
      "userId": "02124395282369883898"
     },
     "user_tz": 180
    },
    "id": "AaSDDO64KtzF",
    "outputId": "95ec8ec2-dfe1-4a5f-8bcf-6bfe25a8a4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando o processo de ETL ---\n",
      "Etapa 1: Extraindo dados dos arquivos CSV...\n",
      "Dados extra√≠dos com sucesso!\n",
      "\n",
      "Etapa 2: Transformando os dados...\n",
      "- Nomes de colunas padronizados.\n",
      "- Colunas harmonizadas entre os datasets.\n",
      "- Colunas de data e hora convertidas para o formato timestamp.\n",
      "- Coluna 'ano' criada.\n",
      "- Tipos de dados das colunas num√©ricas padronizados para inteiro.\n",
      "- Endere√ßos padronizados.\n",
      "- Coluna 'velocidade_max_via' renomeada para 'velocidade_max_via_km_h'.\n",
      "\n",
      "Etapa 3: Carregando os dados transformados...\n",
      "- DataFrames unificados com sucesso.\n",
      "Dados extra√≠dos com sucesso!\n",
      "\n",
      "Etapa 2: Transformando os dados...\n",
      "- Nomes de colunas padronizados.\n",
      "- Colunas harmonizadas entre os datasets.\n",
      "- Colunas de data e hora convertidas para o formato timestamp.\n",
      "- Coluna 'ano' criada.\n",
      "- Tipos de dados das colunas num√©ricas padronizados para inteiro.\n",
      "- Endere√ßos padronizados.\n",
      "- Coluna 'velocidade_max_via' renomeada para 'velocidade_max_via_km_h'.\n",
      "\n",
      "Etapa 3: Carregando os dados transformados...\n",
      "- DataFrames unificados com sucesso.\n",
      "\n",
      "--- Processo de ETL Conclu√≠do! ---\n",
      "A base de dados unificada foi salva como: 'acidentes_unificados_2019-2021.csv'\n",
      "Total de registros na base unificada: 18534\n",
      "\n",
      "Amostra dos 5 primeiros registros da base final:\n",
      "    ano           timestamp natureza_acidente    situacao       bairro  \\\n",
      "0  2019 2019-01-01 00:41:00        SEM V√çTIMA  FINALIZADA        IPSEP   \n",
      "1  2019 2019-01-01 01:37:00        SEM V√çTIMA  FINALIZADA   BOA VIAGEM   \n",
      "2  2019 2019-01-01 14:20:00        SEM V√çTIMA   CANCELADA   BOA VIAGEM   \n",
      "3  2019 2019-01-01 02:53:00        SEM V√çTIMA   CANCELADA  IMBIRIBEIRA   \n",
      "4  2019 2019-01-01 08:17:00        COM V√çTIMA  FINALIZADA     JAQUEIRA   \n",
      "\n",
      "                          endereco  numero    detalhe_endereco_acidente  \\\n",
      "0                        AV RECIFE      -1                 Desconhecido   \n",
      "1       RUA PADRE BERNADINO PESSOA      -1  RUA MINISTRO NELSON HUNGRIA   \n",
      "2  AV ENGENHEIRO DOMINGOS FERREIRA      -1           RUA DOM JOSE LOPES   \n",
      "3            AV GENERAL MAC ARTHUR     100                     RUA JACY   \n",
      "4                   RUA TITO ROSAS      63                 Desconhecido   \n",
      "\n",
      "                                         complemento bairro_cruzamento  ...  \\\n",
      "0                             LADO OPOSTO AO N¬∫ 3257             IPSEP  ...   \n",
      "1                                       Desconhecido        BOA VIAGEM  ...   \n",
      "2  EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQU...        BOA VIAGEM  ...   \n",
      "3                     EM FRENTE A ART LED ILUMINA√á√ÉO       IMBIRIBEIRA  ...   \n",
      "4                            ED. JARDINS DA JAQUEIRA          JAQUEIRA  ...   \n",
      "\n",
      "       sinalizacao condicao_via  conservacao_via     ponto_controle  \\\n",
      "0  Perfeito estado         Seca  Perfeito estado         N√£o existe   \n",
      "1  Perfeito estado         Seca  Perfeito estado  Faixa de pedestre   \n",
      "2              NaN          NaN              NaN                NaN   \n",
      "3              NaN          NaN              NaN                NaN   \n",
      "4  Perfeito estado         Seca  Perfeito estado         N√£o existe   \n",
      "\n",
      "   situacao_placa  velocidade_max_via_km_h  mao_direcao      divisao_via1  \\\n",
      "0   N√£o h√° placas                  60 km/h        √önica  Faixa seccionada   \n",
      "1   N√£o h√° placas                      NaN        √önica        N√£o existe   \n",
      "2             NaN                      NaN          NaN               NaN   \n",
      "3             NaN                      NaN          NaN               NaN   \n",
      "4   N√£o h√° placas                  40 km/h        √önica  Faixa seccionada   \n",
      "\n",
      "   divisao_via2  divisao_via3  \n",
      "0           NaN           NaN  \n",
      "1           NaN           NaN  \n",
      "2           NaN           NaN  \n",
      "3           NaN           NaN  \n",
      "4           NaN           NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "Informa√ß√µes da base final:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18534 entries, 0 to 18533\n",
      "Data columns (total 37 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   ano                        18534 non-null  int64         \n",
      " 1   timestamp                  18516 non-null  datetime64[ns]\n",
      " 2   natureza_acidente          18529 non-null  object        \n",
      " 3   situacao                   18529 non-null  object        \n",
      " 4   bairro                     18347 non-null  object        \n",
      " 5   endereco                   18534 non-null  object        \n",
      " 6   numero                     18534 non-null  int64         \n",
      " 7   detalhe_endereco_acidente  18534 non-null  object        \n",
      " 8   complemento                18534 non-null  object        \n",
      " 9   bairro_cruzamento          18341 non-null  object        \n",
      " 10  num_semaforo               18534 non-null  int64         \n",
      " 11  sentido_via                12651 non-null  object        \n",
      " 12  tipo                       18476 non-null  object        \n",
      " 13  auto                       18534 non-null  int64         \n",
      " 14  moto                       18534 non-null  int64         \n",
      " 15  ciclom                     18534 non-null  int64         \n",
      " 16  ciclista                   18534 non-null  int64         \n",
      " 17  pedestre                   18534 non-null  int64         \n",
      " 18  onibus                     18534 non-null  int64         \n",
      " 19  caminhao                   18534 non-null  int64         \n",
      " 20  viatura                    18534 non-null  int64         \n",
      " 21  outros                     18534 non-null  int64         \n",
      " 22  vitimas                    18534 non-null  int64         \n",
      " 23  vitimasfatais              18534 non-null  int64         \n",
      " 24  acidente_verificado        14266 non-null  object        \n",
      " 25  tempo_clima                14879 non-null  object        \n",
      " 26  situacao_semaforo          14686 non-null  object        \n",
      " 27  sinalizacao                14589 non-null  object        \n",
      " 28  condicao_via               14830 non-null  object        \n",
      " 29  conservacao_via            14606 non-null  object        \n",
      " 30  ponto_controle             13516 non-null  object        \n",
      " 31  situacao_placa             13455 non-null  object        \n",
      " 32  velocidade_max_via_km_h    4609 non-null   object        \n",
      " 33  mao_direcao                14569 non-null  object        \n",
      " 34  divisao_via1               14043 non-null  object        \n",
      " 35  divisao_via2               1449 non-null   object        \n",
      " 36  divisao_via3               248 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(14), object(22)\n",
      "memory usage: 5.2+ MB\n",
      "\n",
      "Etapa 3.3: Inserindo os dados no banco de dados...\n",
      "\n",
      "--- Processo de ETL Conclu√≠do! ---\n",
      "A base de dados unificada foi salva como: 'acidentes_unificados_2019-2021.csv'\n",
      "Total de registros na base unificada: 18534\n",
      "\n",
      "Amostra dos 5 primeiros registros da base final:\n",
      "    ano           timestamp natureza_acidente    situacao       bairro  \\\n",
      "0  2019 2019-01-01 00:41:00        SEM V√çTIMA  FINALIZADA        IPSEP   \n",
      "1  2019 2019-01-01 01:37:00        SEM V√çTIMA  FINALIZADA   BOA VIAGEM   \n",
      "2  2019 2019-01-01 14:20:00        SEM V√çTIMA   CANCELADA   BOA VIAGEM   \n",
      "3  2019 2019-01-01 02:53:00        SEM V√çTIMA   CANCELADA  IMBIRIBEIRA   \n",
      "4  2019 2019-01-01 08:17:00        COM V√çTIMA  FINALIZADA     JAQUEIRA   \n",
      "\n",
      "                          endereco  numero    detalhe_endereco_acidente  \\\n",
      "0                        AV RECIFE      -1                 Desconhecido   \n",
      "1       RUA PADRE BERNADINO PESSOA      -1  RUA MINISTRO NELSON HUNGRIA   \n",
      "2  AV ENGENHEIRO DOMINGOS FERREIRA      -1           RUA DOM JOSE LOPES   \n",
      "3            AV GENERAL MAC ARTHUR     100                     RUA JACY   \n",
      "4                   RUA TITO ROSAS      63                 Desconhecido   \n",
      "\n",
      "                                         complemento bairro_cruzamento  ...  \\\n",
      "0                             LADO OPOSTO AO N¬∫ 3257             IPSEP  ...   \n",
      "1                                       Desconhecido        BOA VIAGEM  ...   \n",
      "2  EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQU...        BOA VIAGEM  ...   \n",
      "3                     EM FRENTE A ART LED ILUMINA√á√ÉO       IMBIRIBEIRA  ...   \n",
      "4                            ED. JARDINS DA JAQUEIRA          JAQUEIRA  ...   \n",
      "\n",
      "       sinalizacao condicao_via  conservacao_via     ponto_controle  \\\n",
      "0  Perfeito estado         Seca  Perfeito estado         N√£o existe   \n",
      "1  Perfeito estado         Seca  Perfeito estado  Faixa de pedestre   \n",
      "2              NaN          NaN              NaN                NaN   \n",
      "3              NaN          NaN              NaN                NaN   \n",
      "4  Perfeito estado         Seca  Perfeito estado         N√£o existe   \n",
      "\n",
      "   situacao_placa  velocidade_max_via_km_h  mao_direcao      divisao_via1  \\\n",
      "0   N√£o h√° placas                  60 km/h        √önica  Faixa seccionada   \n",
      "1   N√£o h√° placas                      NaN        √önica        N√£o existe   \n",
      "2             NaN                      NaN          NaN               NaN   \n",
      "3             NaN                      NaN          NaN               NaN   \n",
      "4   N√£o h√° placas                  40 km/h        √önica  Faixa seccionada   \n",
      "\n",
      "   divisao_via2  divisao_via3  \n",
      "0           NaN           NaN  \n",
      "1           NaN           NaN  \n",
      "2           NaN           NaN  \n",
      "3           NaN           NaN  \n",
      "4           NaN           NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "Informa√ß√µes da base final:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18534 entries, 0 to 18533\n",
      "Data columns (total 37 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   ano                        18534 non-null  int64         \n",
      " 1   timestamp                  18516 non-null  datetime64[ns]\n",
      " 2   natureza_acidente          18529 non-null  object        \n",
      " 3   situacao                   18529 non-null  object        \n",
      " 4   bairro                     18347 non-null  object        \n",
      " 5   endereco                   18534 non-null  object        \n",
      " 6   numero                     18534 non-null  int64         \n",
      " 7   detalhe_endereco_acidente  18534 non-null  object        \n",
      " 8   complemento                18534 non-null  object        \n",
      " 9   bairro_cruzamento          18341 non-null  object        \n",
      " 10  num_semaforo               18534 non-null  int64         \n",
      " 11  sentido_via                12651 non-null  object        \n",
      " 12  tipo                       18476 non-null  object        \n",
      " 13  auto                       18534 non-null  int64         \n",
      " 14  moto                       18534 non-null  int64         \n",
      " 15  ciclom                     18534 non-null  int64         \n",
      " 16  ciclista                   18534 non-null  int64         \n",
      " 17  pedestre                   18534 non-null  int64         \n",
      " 18  onibus                     18534 non-null  int64         \n",
      " 19  caminhao                   18534 non-null  int64         \n",
      " 20  viatura                    18534 non-null  int64         \n",
      " 21  outros                     18534 non-null  int64         \n",
      " 22  vitimas                    18534 non-null  int64         \n",
      " 23  vitimasfatais              18534 non-null  int64         \n",
      " 24  acidente_verificado        14266 non-null  object        \n",
      " 25  tempo_clima                14879 non-null  object        \n",
      " 26  situacao_semaforo          14686 non-null  object        \n",
      " 27  sinalizacao                14589 non-null  object        \n",
      " 28  condicao_via               14830 non-null  object        \n",
      " 29  conservacao_via            14606 non-null  object        \n",
      " 30  ponto_controle             13516 non-null  object        \n",
      " 31  situacao_placa             13455 non-null  object        \n",
      " 32  velocidade_max_via_km_h    4609 non-null   object        \n",
      " 33  mao_direcao                14569 non-null  object        \n",
      " 34  divisao_via1               14043 non-null  object        \n",
      " 35  divisao_via2               1449 non-null   object        \n",
      " 36  divisao_via3               248 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(14), object(22)\n",
      "memory usage: 5.2+ MB\n",
      "\n",
      "Etapa 3.3: Inserindo os dados no banco de dados...\n",
      "- Dados inseridos com sucesso na tabela 'acidentes' do banco SQLite (arquivo 'banco_etl.db').\n",
      "- Dados inseridos com sucesso na tabela 'acidentes' do banco SQLite (arquivo 'banco_etl.db').\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def run_etl_pipeline():\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo de ETL para os dados de acidentes de 2019, 2020 e 2021.\n",
    "    \"\"\"\n",
    "    print(\"--- Iniciando o processo de ETL ---\")\n",
    "\n",
    "    # --- 1. EXTRA√á√ÉO (Extract) ---\n",
    "    # Carregando os tr√™s conjuntos de dados a partir dos arquivos CSV.\n",
    "    try:\n",
    "        print(\"Etapa 1: Extraindo dados dos arquivos CSV...\")\n",
    "        df_2019 = pd.read_csv('data/acidentes2019.csv', delimiter=';')\n",
    "        df_2020 = pd.read_csv('data/acidentes2020.csv', delimiter=';')\n",
    "        df_2021 = pd.read_csv('data/acidentes2021.csv', delimiter=';')\n",
    "        print(\"Dados extra√≠dos com sucesso!\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"ERRO: Arquivo n√£o encontrado. Verifique se os nomes dos arquivos est√£o corretos. Detalhes: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. TRANSFORMA√á√ÉO (Transform) ---\n",
    "    print(\"\\nEtapa 2: Transformando os dados...\")\n",
    "\n",
    "    # 2.1 Padroniza√ß√£o dos nomes das colunas\n",
    "    # O dataset de 2019 tem a coluna 'DATA' em mai√∫sculo. Vamos padronizar para 'data'.\n",
    "    df_2019.rename(columns={'DATA': 'data'}, inplace=True)\n",
    "    print(\"- Nomes de colunas padronizados.\")\n",
    "\n",
    "    # 2.2 Harmoniza√ß√£o das colunas (removendo colunas inconsistentes)\n",
    "    # Colunas presentes em 2019 mas n√£o em 2020/2021\n",
    "    cols_to_drop_2019 = ['endereco_cruzamento', 'numero_cruzamento', 'referencia_cruzamento', 'descricao']\n",
    "    df_2019.drop(columns=[col for col in cols_to_drop_2019 if col in df_2019.columns], inplace=True)\n",
    "\n",
    "    # Coluna 'descricao' presente em 2020 mas n√£o em 2021\n",
    "    if 'descricao' in df_2020.columns:\n",
    "        df_2020.drop(columns=['descricao'], inplace=True)\n",
    "\n",
    "    # A coluna 'tipo' em 2021 est√° no lugar de 'descricao', mas para unificar vamos manter apenas as colunas em comum.\n",
    "    # A base de 2021 n√£o tem a coluna 'descricao', ent√£o n√£o √© necess√°rio fazer nada.\n",
    "\n",
    "    print(\"- Colunas harmonizadas entre os datasets.\")\n",
    "\n",
    "    # Lista dos dataframes para aplicar as transforma√ß√µes em lote\n",
    "    dataframes = [df_2019, df_2020, df_2021]\n",
    "    ano_inicio = 2019 # Precisa ser alterado caso entre anos anteriores no data set\n",
    "\n",
    "    # 2.3 Transforma√ß√£o de data e hora\n",
    "    for i, df in enumerate(dataframes):\n",
    "        ano = ano_inicio + i\n",
    "        # Corrigindo valores de hora inv√°lidos como '24:00:00'\n",
    "        df['hora'] = df['hora'].str.replace('24:00:00', '00:00:00', regex=False)\n",
    "        # Combinando 'data' e 'hora' em uma √∫nica coluna 'timestamp'\n",
    "        # 'coerce' transforma datas inv√°lidas em NaT (Not a Time)\n",
    "        df['timestamp'] = pd.to_datetime(df['data'] + ' ' + df['hora'], errors='coerce')\n",
    "        # Adicionando a coluna 'ano'\n",
    "        df['ano'] = ano\n",
    "        # Removendo as colunas originais\n",
    "        df.drop(columns=['data', 'hora'], inplace=True)\n",
    "\n",
    "    print(\"- Colunas de data e hora convertidas para o formato timestamp.\")\n",
    "    print(\"- Coluna 'ano' criada.\")\n",
    "\n",
    "    # 2.4 Padroniza√ß√£o de tipos de dados num√©ricos\n",
    "    colunas_numericas = [\n",
    "        'auto', 'moto', 'ciclom', 'ciclista', 'pedestre', 'onibus',\n",
    "        'caminhao', 'viatura', 'outros', 'vitimas', 'vitimasfatais'\n",
    "    ]\n",
    "\n",
    "    for df in dataframes:\n",
    "        for col in colunas_numericas:\n",
    "            if col in df.columns:\n",
    "                # Converte para num√©rico, tratando erros, e preenche NaNs com 0\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "                # Converte para inteiro\n",
    "                df[col] = df[col].astype(int)\n",
    "\n",
    "    # Tratamento espec√≠fico para 'num_semaforo' que tem tipos diferentes\n",
    "    for df in dataframes:\n",
    "        if 'num_semaforo' in df.columns:\n",
    "            df['num_semaforo'] = pd.to_numeric(df['num_semaforo'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    print(\"- Tipos de dados das colunas num√©ricas padronizados para inteiro.\")\n",
    "\n",
    "    # Tratamento de endereco\n",
    "    for df in dataframes:\n",
    "        if 'endereco' in df.columns:\n",
    "            df['endereco'] = df['endereco'].str.strip().replace(r'^\\s*$', np.nan, regex=True).fillna('Desconhecido')\n",
    "        if 'detalhe_endereco_acidente' in df.columns:\n",
    "            df['detalhe_endereco_acidente'] = df['detalhe_endereco_acidente'].str.strip().replace(r'^\\s*$', np.nan, regex=True).fillna('Desconhecido')\n",
    "        if 'complemento' in df.columns:\n",
    "            df['complemento'] = df['complemento'].str.strip().replace(r'^\\s*$', np.nan, regex=True).fillna('Desconhecido')\n",
    "        if 'numero' in df.columns:\n",
    "            df['numero'] = pd.to_numeric(df['numero'], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    print(\"- Endere√ßos padronizados.\")\n",
    "\n",
    "    for df in dataframes:\n",
    "        if 'velocidade_max_via' in df.columns:\n",
    "            df.rename(columns={'velocidade_max_via': 'velocidade_max_via_km_h'}, inplace=True)\n",
    "    print(\"- Coluna 'velocidade_max_via' renomeada para 'velocidade_max_via_km_h'.\")\n",
    "\n",
    "    # --- 3. CARGA (Load) ---\n",
    "    print(\"\\nEtapa 3: Carregando os dados transformados...\")\n",
    "\n",
    "    # 3.1 Unifica√ß√£o dos DataFrames\n",
    "    # Concatenando os tr√™s dataframes em um s√≥\n",
    "    df_unificado = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"- DataFrames unificados com sucesso.\")\n",
    "\n",
    "    # Reordenando colunas para colocar 'ano' e 'timestamp' no in√≠cio\n",
    "    cols = ['ano', 'timestamp'] + [col for col in df_unificado.columns if col not in ['ano', 'timestamp']]\n",
    "    df_unificado = df_unificado[cols]\n",
    "\n",
    "    # 3.2 Salvando o resultado em um novo arquivo CSV\n",
    "    output_filename = 'acidentes_unificados_2019-2021.csv'\n",
    "    df_unificado.to_csv(output_filename, index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "    print(f\"\\n--- Processo de ETL Conclu√≠do! ---\")\n",
    "    print(f\"A base de dados unificada foi salva como: '{output_filename}'\")\n",
    "    print(f\"Total de registros na base unificada: {len(df_unificado)}\")\n",
    "    print(\"\\nAmostra dos 5 primeiros registros da base final:\")\n",
    "    print(df_unificado.head())\n",
    "    print(\"\\nInforma√ß√µes da base final:\")\n",
    "    df_unificado.info()\n",
    "\n",
    "    # 3.3 Inserindo no banco de dados\n",
    "    print(\"\\nEtapa 3.3: Inserindo os dados no banco de dados...\")\n",
    "\n",
    "    # criando um arquivo .db\n",
    "    nome_do_banco_de_dados2 = \"banco_etl.db\"\n",
    "    nome_tabela = 'acidentes'\n",
    "\n",
    "    engine = create_engine(f'sqlite:///{nome_do_banco_de_dados2}')\n",
    "\n",
    "    df_unificado.to_sql(nome_tabela,\n",
    "                        con=engine,\n",
    "                        if_exists='replace',\n",
    "                        index=False)\n",
    "\n",
    "    print(f\"- Dados inseridos com sucesso na tabela '{nome_tabela}' do banco SQLite (arquivo '{nome_do_banco_de_dados2}').\")\n",
    "# Executando a fun√ß√£o principal do pipeline\n",
    "run_etl_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4yTS38lrPrG"
   },
   "source": [
    "# ETAPA ELT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Iniciando transforma√ß√µes no banco de dados (ELT - PLs)...\n",
      "- Coluna 'timestamp' preenchida com DATA e hora.\n",
      "- Endere√ßo e n√∫mero tratados.\n",
      "- Endere√ßo e n√∫mero tratados.\n",
      "--- Verifica√ß√£o Final do Processo ELT ---\n",
      "A tabela final 'dados_brutos_sinistros' cont√©m um total de 18534 registros.\n",
      "\n",
      "Contagem de registros por ano de origem do dado:\n",
      "--- Verifica√ß√£o Final do Processo ELT ---\n",
      "A tabela final 'dados_brutos_sinistros' cont√©m um total de 18534 registros.\n",
      "\n",
      "Contagem de registros por ano de origem do dado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>hora</th>\n",
       "      <th>natureza_acidente</th>\n",
       "      <th>situacao</th>\n",
       "      <th>bairro</th>\n",
       "      <th>endereco</th>\n",
       "      <th>numero</th>\n",
       "      <th>detalhe_endereco_acidente</th>\n",
       "      <th>complemento</th>\n",
       "      <th>endereco_cruzamento</th>\n",
       "      <th>...</th>\n",
       "      <th>conservacao_via</th>\n",
       "      <th>ponto_controle</th>\n",
       "      <th>situacao_placa</th>\n",
       "      <th>mao_direcao</th>\n",
       "      <th>divisao_via1</th>\n",
       "      <th>divisao_via2</th>\n",
       "      <th>divisao_via3</th>\n",
       "      <th>ano_do_dado</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>velocidade_max_via_km_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:41:00</td>\n",
       "      <td>SEM V√çTIMA</td>\n",
       "      <td>FINALIZADA</td>\n",
       "      <td>IPSEP</td>\n",
       "      <td>AV RECIFE</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>LADO OPOSTO AO N¬∫ 3257</td>\n",
       "      <td>AV RECIFE</td>\n",
       "      <td>...</td>\n",
       "      <td>Perfeito estado</td>\n",
       "      <td>N√£o existe</td>\n",
       "      <td>N√£o h√° placas</td>\n",
       "      <td>√önica</td>\n",
       "      <td>Faixa seccionada</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01 00:41:00</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:37:00</td>\n",
       "      <td>SEM V√çTIMA</td>\n",
       "      <td>FINALIZADA</td>\n",
       "      <td>BOA VIAGEM</td>\n",
       "      <td>RUA PADRE BERNADINO PESSOA</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>RUA MINISTRO NELSON HUNGRIA</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>RUA PADRE BERNADINO PESSOA</td>\n",
       "      <td>...</td>\n",
       "      <td>Perfeito estado</td>\n",
       "      <td>Faixa de pedestre</td>\n",
       "      <td>N√£o h√° placas</td>\n",
       "      <td>√önica</td>\n",
       "      <td>N√£o existe</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01 01:37:00</td>\n",
       "      <td>Desconhecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>14:20:00</td>\n",
       "      <td>SEM V√çTIMA</td>\n",
       "      <td>CANCELADA</td>\n",
       "      <td>BOA VIAGEM</td>\n",
       "      <td>AV ENGENHEIRO DOMINGOS FERREIRA</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>RUA DOM JOSE LOPES</td>\n",
       "      <td>EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQU...</td>\n",
       "      <td>AV ENGENHEIRO DOMINGOS FERREIRA</td>\n",
       "      <td>...</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01 14:20:00</td>\n",
       "      <td>Desconhecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>02:53:00</td>\n",
       "      <td>SEM V√çTIMA</td>\n",
       "      <td>CANCELADA</td>\n",
       "      <td>IMBIRIBEIRA</td>\n",
       "      <td>AV GENERAL MAC ARTHUR</td>\n",
       "      <td>100</td>\n",
       "      <td>RUA JACY</td>\n",
       "      <td>EM FRENTE A ART LED ILUMINA√á√ÉO</td>\n",
       "      <td>AV GENERAL MAC ARTHUR</td>\n",
       "      <td>...</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01 02:53:00</td>\n",
       "      <td>Desconhecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>08:17:00</td>\n",
       "      <td>COM V√çTIMA</td>\n",
       "      <td>FINALIZADA</td>\n",
       "      <td>JAQUEIRA</td>\n",
       "      <td>RUA TITO ROSAS</td>\n",
       "      <td>63</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>ED. JARDINS DA JAQUEIRA</td>\n",
       "      <td>RUA TITO ROSAS</td>\n",
       "      <td>...</td>\n",
       "      <td>Perfeito estado</td>\n",
       "      <td>N√£o existe</td>\n",
       "      <td>N√£o h√° placas</td>\n",
       "      <td>√önica</td>\n",
       "      <td>Faixa seccionada</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01 08:17:00</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18529</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>11:36:00</td>\n",
       "      <td>COM V√çTIMA</td>\n",
       "      <td>FINALIZADA</td>\n",
       "      <td>EST√ÇNCIA</td>\n",
       "      <td>AV RECIFE</td>\n",
       "      <td>673</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>EM FRENTE AO LABORATORIO CERPE</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>...</td>\n",
       "      <td>Perfeito estado</td>\n",
       "      <td>N√£o existe</td>\n",
       "      <td>R-6a</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Faixa cont√≠nua</td>\n",
       "      <td>Faixa seccionada</td>\n",
       "      <td>Canteiro central</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-12-31 11:36:00</td>\n",
       "      <td>Desconhecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18530</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>12:56:00</td>\n",
       "      <td>COM V√çTIMA</td>\n",
       "      <td>FINALIZADA</td>\n",
       "      <td>V√ÅRZEA</td>\n",
       "      <td>RUA GASTAO VIDIGAL</td>\n",
       "      <td>125</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>EM FRENTE AO MOTEL DO NINJA</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>...</td>\n",
       "      <td>Perfeito estado</td>\n",
       "      <td>N√£o existe</td>\n",
       "      <td>N√£o h√° placas</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Faixa seccionada</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-12-31 12:56:00</td>\n",
       "      <td>Desconhecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18531</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>COM V√çTIMA</td>\n",
       "      <td>FINALIZADA</td>\n",
       "      <td>TORRE√ÉO</td>\n",
       "      <td>AV NORTE MIGUEL ARRAES DE ALENCAR</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>RUA NATIVIDADE SALDANHA</td>\n",
       "      <td>ACIDENTE COM VIT√çMA NA PRA√áA DA PICANHA / SOLI...</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>...</td>\n",
       "      <td>Perfeito estado</td>\n",
       "      <td>Faixa de pedestre</td>\n",
       "      <td>Outras</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Faixa cont√≠nua</td>\n",
       "      <td>Faixa seccionada</td>\n",
       "      <td>Canteiro central</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-12-31 15:00:00</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18532</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>20:44:00</td>\n",
       "      <td>COM V√çTIMA</td>\n",
       "      <td>CANCELADA</td>\n",
       "      <td>PRADO</td>\n",
       "      <td>RUA PANDIA CALOGERAS</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>PROX AO HABIBIS</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>...</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-12-31 20:44:00</td>\n",
       "      <td>Desconhecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18533</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>20:56:00</td>\n",
       "      <td>COM V√çTIMA</td>\n",
       "      <td>CANCELADA</td>\n",
       "      <td>IPSEP</td>\n",
       "      <td>RUA JEAN EMILE FAVRE</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>ENFRENTE A SO MOTO E FARMACIA DIARIAMENTE</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>...</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-12-31 20:56:00</td>\n",
       "      <td>Desconhecido</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18534 rows √ó 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATA      hora natureza_acidente    situacao       bairro  \\\n",
       "0      2019-01-01  00:41:00        SEM V√çTIMA  FINALIZADA        IPSEP   \n",
       "1      2019-01-01  01:37:00        SEM V√çTIMA  FINALIZADA   BOA VIAGEM   \n",
       "2      2019-01-01  14:20:00        SEM V√çTIMA   CANCELADA   BOA VIAGEM   \n",
       "3      2019-01-01  02:53:00        SEM V√çTIMA   CANCELADA  IMBIRIBEIRA   \n",
       "4      2019-01-01  08:17:00        COM V√çTIMA  FINALIZADA     JAQUEIRA   \n",
       "...           ...       ...               ...         ...          ...   \n",
       "18529  2021-12-31  11:36:00        COM V√çTIMA  FINALIZADA     EST√ÇNCIA   \n",
       "18530  2021-12-31  12:56:00        COM V√çTIMA  FINALIZADA       V√ÅRZEA   \n",
       "18531  2021-12-31  15:00:00        COM V√çTIMA  FINALIZADA      TORRE√ÉO   \n",
       "18532  2021-12-31  20:44:00        COM V√çTIMA   CANCELADA        PRADO   \n",
       "18533  2021-12-31  20:56:00        COM V√çTIMA   CANCELADA        IPSEP   \n",
       "\n",
       "                                endereco        numero  \\\n",
       "0                              AV RECIFE  Desconhecido   \n",
       "1             RUA PADRE BERNADINO PESSOA  Desconhecido   \n",
       "2        AV ENGENHEIRO DOMINGOS FERREIRA  Desconhecido   \n",
       "3                  AV GENERAL MAC ARTHUR           100   \n",
       "4                         RUA TITO ROSAS            63   \n",
       "...                                  ...           ...   \n",
       "18529                          AV RECIFE           673   \n",
       "18530                 RUA GASTAO VIDIGAL           125   \n",
       "18531  AV NORTE MIGUEL ARRAES DE ALENCAR  Desconhecido   \n",
       "18532               RUA PANDIA CALOGERAS  Desconhecido   \n",
       "18533               RUA JEAN EMILE FAVRE  Desconhecido   \n",
       "\n",
       "         detalhe_endereco_acidente  \\\n",
       "0                     Desconhecido   \n",
       "1      RUA MINISTRO NELSON HUNGRIA   \n",
       "2               RUA DOM JOSE LOPES   \n",
       "3                         RUA JACY   \n",
       "4                     Desconhecido   \n",
       "...                            ...   \n",
       "18529                 Desconhecido   \n",
       "18530                 Desconhecido   \n",
       "18531      RUA NATIVIDADE SALDANHA   \n",
       "18532                 Desconhecido   \n",
       "18533                 Desconhecido   \n",
       "\n",
       "                                             complemento  \\\n",
       "0                                 LADO OPOSTO AO N¬∫ 3257   \n",
       "1                                           Desconhecido   \n",
       "2      EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQU...   \n",
       "3                         EM FRENTE A ART LED ILUMINA√á√ÉO   \n",
       "4                                ED. JARDINS DA JAQUEIRA   \n",
       "...                                                  ...   \n",
       "18529                     EM FRENTE AO LABORATORIO CERPE   \n",
       "18530                        EM FRENTE AO MOTEL DO NINJA   \n",
       "18531  ACIDENTE COM VIT√çMA NA PRA√áA DA PICANHA / SOLI...   \n",
       "18532                                    PROX AO HABIBIS   \n",
       "18533          ENFRENTE A SO MOTO E FARMACIA DIARIAMENTE   \n",
       "\n",
       "                   endereco_cruzamento  ...  conservacao_via  \\\n",
       "0                            AV RECIFE  ...  Perfeito estado   \n",
       "1           RUA PADRE BERNADINO PESSOA  ...  Perfeito estado   \n",
       "2      AV ENGENHEIRO DOMINGOS FERREIRA  ...     Desconhecido   \n",
       "3                AV GENERAL MAC ARTHUR  ...     Desconhecido   \n",
       "4                       RUA TITO ROSAS  ...  Perfeito estado   \n",
       "...                                ...  ...              ...   \n",
       "18529                     Desconhecido  ...  Perfeito estado   \n",
       "18530                     Desconhecido  ...  Perfeito estado   \n",
       "18531                     Desconhecido  ...  Perfeito estado   \n",
       "18532                     Desconhecido  ...     Desconhecido   \n",
       "18533                     Desconhecido  ...     Desconhecido   \n",
       "\n",
       "          ponto_controle situacao_placa   mao_direcao      divisao_via1  \\\n",
       "0             N√£o existe  N√£o h√° placas         √önica  Faixa seccionada   \n",
       "1      Faixa de pedestre  N√£o h√° placas         √önica        N√£o existe   \n",
       "2           Desconhecido   Desconhecido  Desconhecido      Desconhecido   \n",
       "3           Desconhecido   Desconhecido  Desconhecido      Desconhecido   \n",
       "4             N√£o existe  N√£o h√° placas         √önica  Faixa seccionada   \n",
       "...                  ...            ...           ...               ...   \n",
       "18529         N√£o existe           R-6a         Dupla    Faixa cont√≠nua   \n",
       "18530         N√£o existe  N√£o h√° placas         Dupla  Faixa seccionada   \n",
       "18531  Faixa de pedestre         Outras         Dupla    Faixa cont√≠nua   \n",
       "18532       Desconhecido   Desconhecido  Desconhecido      Desconhecido   \n",
       "18533       Desconhecido   Desconhecido  Desconhecido      Desconhecido   \n",
       "\n",
       "           divisao_via2      divisao_via3  ano_do_dado            TimeStamp  \\\n",
       "0          Desconhecido      Desconhecido         2019  2019-01-01 00:41:00   \n",
       "1          Desconhecido      Desconhecido         2019  2019-01-01 01:37:00   \n",
       "2          Desconhecido      Desconhecido         2019  2019-01-01 14:20:00   \n",
       "3          Desconhecido      Desconhecido         2019  2019-01-01 02:53:00   \n",
       "4          Desconhecido      Desconhecido         2019  2019-01-01 08:17:00   \n",
       "...                 ...               ...          ...                  ...   \n",
       "18529  Faixa seccionada  Canteiro central         2021  2021-12-31 11:36:00   \n",
       "18530      Desconhecido      Desconhecido         2021  2021-12-31 12:56:00   \n",
       "18531  Faixa seccionada  Canteiro central         2021  2021-12-31 15:00:00   \n",
       "18532      Desconhecido      Desconhecido         2021  2021-12-31 20:44:00   \n",
       "18533      Desconhecido      Desconhecido         2021  2021-12-31 20:56:00   \n",
       "\n",
       "       velocidade_max_via_km_h  \n",
       "0                           60  \n",
       "1                 Desconhecido  \n",
       "2                 Desconhecido  \n",
       "3                 Desconhecido  \n",
       "4                           40  \n",
       "...                        ...  \n",
       "18529             Desconhecido  \n",
       "18530             Desconhecido  \n",
       "18531                       60  \n",
       "18532             Desconhecido  \n",
       "18533             Desconhecido  \n",
       "\n",
       "[18534 rows x 43 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INICIANDO A SUBIDA DOS DADOS BRUTOS DE 2019 AT√â 2021, Utilizando as bibliotecas panda e sqlalchemy\n",
    "\n",
    "# --- CONFIGURA√á√ÉO---\n",
    "# Nome dos arquivos CSV, Importante copiar os arquivos como caminho para executar\n",
    "lista_arquivos_csv = ['data/acidentes2019.csv', 'data/acidentes2020.csv', 'data/acidentes2021.csv']\n",
    "\n",
    "# Nome do arquivo do banco de dados\n",
    "nome_do_banco_de_dados = 'banco_elt.db'\n",
    "\n",
    "# Nome da tabela onde os dados brutos ser√£o guardados\n",
    "nome_da_tabela_consolidada = 'dados_brutos_sinistros'\n",
    "\n",
    "# Conectar ao banco de dados\n",
    "engine = create_engine(f'sqlite:///{nome_do_banco_de_dados}')\n",
    "\n",
    "for i, nome_arquivo in enumerate(lista_arquivos_csv):\n",
    "  # Lendo os arquivos csv para um dataframe (EXTRACT)\n",
    "  df_temp  = pd.read_csv(nome_arquivo, sep=';', encoding='utf-8')\n",
    "  #Adicionar uma coluna para saber a origem do dado\n",
    "  ano = nome_arquivo.replace('acidentes', '').replace('.csv', '').replace('/content/sample_data/Arquivos base de dados/','').replace('data/','')\n",
    "  df_temp['ano_do_dado'] = int(ano)\n",
    "\n",
    "  # CARREGAMENTO (LOAD)\n",
    "  # Define a estrat√©gia: 'replace' para o primeiro arquivo, 'append' para os demais.\n",
    "  if i == 0:\n",
    "        modo_de_insercao = 'replace'\n",
    "  else:\n",
    "      modo_de_insercao = 'append'\n",
    "\n",
    "  df_temp.to_sql(\n",
    "      nome_da_tabela_consolidada,\n",
    "      con=engine,\n",
    "      if_exists=modo_de_insercao,\n",
    "      index=False\n",
    "  )\n",
    "\n",
    "#fazendo as transforma√ß√µes dentro do banco\n",
    "with engine.connect() as conn:\n",
    "\n",
    "        print(\"\\nüîÑ Iniciando transforma√ß√µes no banco de dados (ELT - PLs)...\")\n",
    "        #criar coluna TimeStamp\n",
    "        conn.execute(text(\"\"\"\n",
    "                ALTER TABLE dados_brutos_sinistros ADD COLUMN TimeStamp TEXT;\n",
    "            \"\"\"))\n",
    "\n",
    "        #tratando 2 dados espec√≠ficos que foram mal prenchidos nos dados de 2019 linhas 8378 e 10215 que ser√£o considerados nulo\n",
    "        conn.execute(text(f\"\"\"\n",
    "            UPDATE dados_brutos_sinistros\n",
    "            SET hora = null\n",
    "            WHERE hora in (\"48:00:00\",\"1049592:00:00\");\n",
    "        \"\"\"))\n",
    "\n",
    "        #Preencher a coluna timestamp com DATA + hora\n",
    "        conn.execute(text(\"\"\"\n",
    "            UPDATE dados_brutos_sinistros\n",
    "            SET TimeStamp =\n",
    "                coalesce(data, DATA) || ' ' ||\n",
    "                CASE\n",
    "                    WHEN hora = '24:00:00' THEN '00:00:00'\n",
    "                    ELSE hora\n",
    "                END;\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "        print(\"- Coluna 'timestamp' preenchida com DATA e hora.\")\n",
    "\n",
    "        #Tratar campo de n√∫mero, transformando em -1\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            UPDATE dados_brutos_sinistros\n",
    "            SET numero = CASE\n",
    "                WHEN numero IS NULL OR TRIM(numero) = '' THEN \"Desconhecido\"\n",
    "                ELSE numero\n",
    "            END;\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "        print(\"- Endere√ßo e n√∫mero tratados.\")\n",
    "\n",
    "        colunas_numericas = ['auto', 'moto', 'ciclom', 'ciclista', 'pedestre',\n",
    "                             'onibus', 'caminhao', 'viatura', 'outros',\n",
    "                             'vitimas', 'vitimasfatais', 'num_semaforo']\n",
    "\n",
    "        #Padronizando colunas que s√£o n√∫mericas, transformando em 0 caso a coluna n√£o exista ou passando para inteiro\n",
    "        for col in colunas_numericas:\n",
    "            conn.execute(text(f\"\"\"\n",
    "                UPDATE dados_brutos_sinistros\n",
    "                SET {col} = CASE\n",
    "                    WHEN TRIM({col}) = '' OR {col} IS NULL THEN 0\n",
    "                    ELSE CAST({col} as INTEGER)\n",
    "                END;\n",
    "            \"\"\"))\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "        #Definindo que caso n√£o haja informa√ß√£o se houveram v√≠timas, colocar como se n√£o houvessem\n",
    "        conn.execute(text(f\"\"\"\n",
    "            UPDATE dados_brutos_sinistros\n",
    "            SET natureza_acidente = 'SEM V√çTIMA'\n",
    "            WHERE natureza_acidente IS NULL;\n",
    "        \"\"\"))\n",
    "\n",
    "        #criando coluna contendo as colunas dos bancos de dados que s√£o compostas por elementos de texto para substituir por desconhecido no caso de serem vazias ou nulos\n",
    "        colunas_strings =['bairro','endereco','detalhe_endereco_acidente','complemento','endereco_cruzamento','conservacao_via','ponto_controle','situacao_placa','velocidade_max_via','velocidade_max_via','divisao_via1','divisao_via2','divisao_via3','bairro_cruzamento','tipo','acidente_verificado','tempo_clima','situacao_semaforo','sinalizacao','sentido_via','condicao_via','mao_direcao']\n",
    "        for col in colunas_strings:\n",
    "            conn.execute(text(f\"\"\"\n",
    "                UPDATE dados_brutos_sinistros\n",
    "                SET {col} = COALESCE(NULLIF(TRIM({col}), ''), 'Desconhecido');\n",
    "            \"\"\"))\n",
    "        conn.commit()\n",
    "\n",
    "        #retirando km/h da velocidade maxima da via, para deixar apenas n√∫meros\n",
    "        conn.execute(text(\"\"\"\n",
    "            UPDATE dados_brutos_sinistros\n",
    "            SET velocidade_max_via = CASE\n",
    "                WHEN velocidade_max_via LIKE '%km/h%' THEN TRIM(REPLACE(velocidade_max_via, 'km/h', ''))\n",
    "                ELSE velocidade_max_via\n",
    "            END;\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "\n",
    "        #criando uma nova coluna de velocidade_max_via_km_h\n",
    "        conn.execute(text(\"\"\"\n",
    "          ALTER TABLE dados_brutos_sinistros\n",
    "          ADD COLUMN velocidade_max_via_km_h TEXT;\n",
    "       \"\"\"))\n",
    "\n",
    "        conn.commit()\n",
    "         #Copia os dados da coluna antiga para a nova\n",
    "        conn.execute(text(\"\"\"\n",
    "          UPDATE dados_brutos_sinistros\n",
    "          SET velocidade_max_via_km_h = velocidade_max_via;\n",
    "      \"\"\"))\n",
    "        conn.commit()\n",
    "\n",
    "        #Determinando que quando o dado estiver entre 0 e 9 ser√° considerado inteiro, assim permanecendo o dado Desconhecido quando n√£o h√° dados\n",
    "        conn.execute(text(\"\"\"\n",
    "          UPDATE dados_brutos_sinistros\n",
    "          SET velocidade_max_via_km_h =\n",
    "              CASE\n",
    "                  WHEN TRIM(velocidade_max_via_km_h) GLOB '[0-9]*'\n",
    "                  THEN CAST(velocidade_max_via_km_h AS INTEGER)\n",
    "                  ELSE 'Desconhecido'\n",
    "              END;\n",
    "      \"\"\"))\n",
    "        conn.commit()\n",
    "\n",
    "        #Tirando a coluna antiga\n",
    "        conn.execute(text(\n",
    "            \"\"\"\n",
    "            ALTER TABLE dados_brutos_sinistros\n",
    "            DROP COLUMN velocidade_max_via;\n",
    "            \"\"\"\n",
    "        ))\n",
    "\n",
    "\n",
    "\n",
    "# Verifica√ß√£o Final\n",
    "print(\"--- Verifica√ß√£o Final do Processo ELT ---\")\n",
    "\n",
    "# Contar o total de registros na tabela consolidada\n",
    "total_registros = pd.read_sql(f\"SELECT COUNT(*) FROM {nome_da_tabela_consolidada}\", engine).iloc[0,0]\n",
    "print(f\"A tabela final '{nome_da_tabela_consolidada}' cont√©m um total de {total_registros} registros.\")\n",
    "\n",
    "# Agrupar por ano para confirmar que os dados dos 3 arquivos foram carregados\n",
    "print(\"\\nContagem de registros por ano de origem do dado:\")\n",
    "df_verificacao = pd.read_sql(f'SELECT ano_do_dado, COUNT(*) as total_de_linhas FROM {nome_da_tabela_consolidada} GROUP BY ano_do_dado', engine)\n",
    "\n",
    "\n",
    "#selecionar todos os dados\n",
    "df_all = pd.read_sql(f'SELECT * FROM {nome_da_tabela_consolidada} ', engine)\n",
    "df_all\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18794,
     "status": "ok",
     "timestamp": 1754516990947,
     "user": {
      "displayName": "Guilherme Campelo",
      "userId": "02124395282369883898"
     },
     "user_tz": 180
    },
    "id": "wwp0pArBlJjp",
    "outputId": "2c4fcd9f-eb83-45b1-85d6-403f95a7cb9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando o arquivo Excel: dados_brutos_sinistros_consolidados.xlsx...\n",
      "‚úÖ Arquivo 'dados_brutos_sinistros_consolidados.xlsx' gerado com sucesso!\n",
      "‚úÖ Arquivo 'dados_brutos_sinistros_consolidados.xlsx' gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- C√ìDIGO PARA GERAR O ARQUIVO XLSX ---\n",
    "# (Execute esta c√©lula ap√≥s ter executado seu c√≥digo que cria o DataFrame 'df_all')\n",
    "\n",
    "# Nome que voc√™ deseja para o arquivo Excel de sa√≠da\n",
    "nome_do_arquivo_saida = 'dados_brutos_sinistros_consolidados.xlsx'\n",
    "\n",
    "print(f\"Gerando o arquivo Excel: {nome_do_arquivo_saida}...\")\n",
    "\n",
    "df_all.to_excel(\n",
    "    nome_do_arquivo_saida,\n",
    "    sheet_name='Dados de Sinistros',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Arquivo '{nome_do_arquivo_saida}' gerado com sucesso!\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
